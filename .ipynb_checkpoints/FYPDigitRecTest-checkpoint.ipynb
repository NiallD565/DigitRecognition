{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import basename\n",
    "\n",
    "yTrain = []\n",
    "for filename in glob.glob('Dataset/*.png'): #assuming png\n",
    "    im = Image.open(filename)\n",
    "    label = (filename.split(\"_\")[1])\n",
    "    #print(label)\n",
    "    yTrain.append(label)\n",
    "    im.close()\n",
    "\n",
    "#print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flat_Image_List = [] # new list containing flatten image arrays\n",
    "#for img in yTrain: # iterate over the images contained in the directory\n",
    "for filename in glob.glob('Dataset/*.png'):\n",
    "    im = Image.open(filename)\n",
    "    img = np.reshape(im, (12288))\n",
    "    flat_Image_List.append(img) # Append to the list \n",
    "    #plt.imshow(img)\n",
    "    im.close()\n",
    "    #print(flat_Image_List)\n",
    "#print(flat_Image_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = 12288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "xTrain = array(flat_Image_List)\n",
    "\n",
    "#print(flat_Image_List)\n",
    "print(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts RGB to a range between 0-1\n",
    "xTrain = xTrain/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = np.reshape(xTrain,(len(xTrain), 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "(73055,)\n"
     ]
    }
   ],
   "source": [
    "noLabels = len(np.unique(yTrain))\n",
    "print(noLabels)\n",
    "yTrain = np.array(yTrain)\n",
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E']\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = ['0', '1', '2','3', '4','5', '6','7', '8', '9', 'A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "values = array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "labelData = label_encoder.fit_transform(yTrain)\n",
    "print(labelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "labelData = labelData.reshape(len(labelData), 1)\n",
    "labelData = onehot_encoder.fit_transform(labelData)\n",
    "print(labelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# invert example\n",
    "inverted = label_encoder.inverse_transform([argmax(labelData[10, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... 'E' 'E' 'E']\n"
     ]
    }
   ],
   "source": [
    "yTrain.shape\n",
    "print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n"
     ]
    }
   ],
   "source": [
    "# For encoding categorical variables and pre processing.\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(yTrain)\n",
    "outputs = encoder.transform(yTrain)\n",
    "\n",
    "\n",
    "inputs = xTrain\n",
    "inputs.shape\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               15745280  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                765       \n",
      "=================================================================\n",
      "Total params: 15,760,687\n",
      "Trainable params: 15,760,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------- MODEL -------\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Adapted from: https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d?fbclid=IwAR01njT_lhc2ZZOySJnWhmq8z9iWUcKjefacuRj_bI1rJbmR0NCW1cr-ao4\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "# Add a hidden layer with 784 neurons.\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(256, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=tf.nn.relu))\n",
    "\n",
    "# Add a 15 neuron output layer.\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73055/73055 [==============================] - 979s 13ms/step - loss: 2.2771 - acc: 0.3021\n",
      "Epoch 2/10\n",
      "73055/73055 [==============================] - 685s 9ms/step - loss: 1.4432 - acc: 0.4957\n",
      "Epoch 3/10\n",
      "73055/73055 [==============================] - 660s 9ms/step - loss: 1.1793 - acc: 0.5885\n",
      "Epoch 4/10\n",
      "73055/73055 [==============================] - 684s 9ms/step - loss: 0.7160 - acc: 0.7662\n",
      "Epoch 5/10\n",
      "13500/73055 [====>.........................] - ETA: 9:05 - loss: 0.5131 - acc: 0.8387"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Number of Epoch is the amount of times the training set is put through the model\n",
    "# The batch size is the amount of images the models processes at one time\n",
    "model.fit(xTrain,labelData, epochs=10, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(xTest, yTest, verbose = 0)\n",
    "\n",
    "print(\"Error percentage: %.2f%%\" %(100 - score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
