{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import basename\n",
    "\n",
    "image_Lbl_list = []\n",
    "for filename in glob.glob('Dataset/*.png'): #assuming png\n",
    "    im = Image.open(filename)\n",
    "    label = (filename.split(\"_\")[1])\n",
    "    #print(label)\n",
    "    image_Lbl_list.append(label)\n",
    "    im.close()\n",
    "\n",
    "#print(image_Lbl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flat_Image_List = [] # new list containing flatten image arrays\n",
    "#for img in image_Lbl_list: # iterate over the images contained in the directory\n",
    "for filename in glob.glob('Dataset/*.png'):\n",
    "    im = Image.open(filename)\n",
    "    img = np.reshape(im, (12288)) # flattened each imag (3 per each pixel)\n",
    "    flat_Image_List.append(img) # Append to the list \n",
    "    #plt.imshow(img)\n",
    "    im.close()\n",
    "    #print(flat_Image_List)\n",
    "\n",
    "#print(flat_Image_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 15\n",
    "imageSize = 12288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "xTrain = array(flat_Image_List)\n",
    "\n",
    "#print(flat_Image_List)\n",
    "print(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 897699840 into shape (73055,64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fd85d23d247d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 897699840 into shape (73055,64,64,1)"
     ]
    }
   ],
   "source": [
    "xTrain = xTrain.reshape(xTrain.shape[0], 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73055, 12288)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For encoding categorical variables and pre processing.\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(image_Lbl_list)\n",
    "outputs = encoder.transform(image_Lbl_list)\n",
    "\n",
    "#xTrain.reshape(100, 12288)\n",
    "\n",
    "inputs = xTrain\n",
    "#inputs.reshape(len(xTrain), imageSize)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ------- MODEL -------\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "# Add a hidden layer with 784 neurons.\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "# Add a 15 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=inputs,y=outputs, epochs=10, batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = np.array(list(flat_Image_List[:])).reshape(100, 49152).astype(np.uint8)\n",
    "image_Lbl_list =  np.array(list(image_Lbl_list[:])).astype(np.uint8)\n",
    "\n",
    "xTrain[1]\n",
    "#print(image_Lbl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Number of Epoch is the amount of times the training set is put through the model\n",
    "# The batch size is the amount of images the models processes at one time\n",
    "model.fit(inputs, outputs, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = np.array(list(flat_Image_List[:])).reshape(100, 49152).astype(np.uint8)\n",
    "image_Lbl_list =  np.array(list(image_Lbl_list[:])).astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
