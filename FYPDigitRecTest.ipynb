{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import basename\n",
    "\n",
    "image_label_list = []\n",
    "for filename in glob.glob('Dataset/*.png'): #assuming png\n",
    "    im = Image.open(filename)\n",
    "    label = (filename.split(\"_\")[1])\n",
    "    #print(label)\n",
    "    image_label_list.append(label)\n",
    "    im.close()\n",
    "\n",
    "#print(image_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flat_Image_List = [] # new list containing flatten image arrays\n",
    "for filename in glob.glob('Dataset/*.png'):# iterate over the images contained in the directory\n",
    "    im = Image.open(filename)\n",
    "    img = np.reshape(im, (12288))\n",
    "    flat_Image_List.append(img) # Append to the list \n",
    "    #plt.imshow(img)\n",
    "    im.close()\n",
    "    #print(flat_Image_List)\n",
    "#print(flat_Image_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = 12288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "image_array = array(flat_Image_List)\n",
    "\n",
    "#print(flat_Image_List)\n",
    "#print(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73055"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.reshape(image_array,(len(image_array), 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = image_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts RGB to a range between 0-1\n",
    "image_array = image_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "(73055,)\n"
     ]
    }
   ],
   "source": [
    "noLabels = len(np.unique(image_label_list))\n",
    "print(noLabels)\n",
    "label_array = np.array(image_label_list)\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E']\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = ['0', '1', '2','3', '4','5', '6','7', '8', '9', 'A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "values = array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "labelData = label_encoder.fit_transform(label_array)\n",
    "print(labelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "labelData = labelData.reshape(len(labelData), 1)\n",
    "labelData = onehot_encoder.fit_transform(labelData)\n",
    "print(labelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(labelData[68000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# invert example\n",
    "inverted = label_encoder.inverse_transform([argmax(labelData[68000, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... 'E' 'E' 'E']\n"
     ]
    }
   ],
   "source": [
    "label_array.shape\n",
    "print(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.Random(4).shuffle(image_array)\n",
    "random.Random(4).shuffle(labelData)\n",
    "#print(image_array)\n",
    "#print(labelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62096, 64, 64, 3) (62096, 15)\n",
      "(10959, 64, 64, 3) (10959, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array, labelData, test_size=0.15)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               15745280  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                765       \n",
      "=================================================================\n",
      "Total params: 15,760,687\n",
      "Trainable params: 15,760,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ------- MODEL -------\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Adapted from: https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d?fbclid=IwAR01njT_lhc2ZZOySJnWhmq8z9iWUcKjefacuRj_bI1rJbmR0NCW1cr-ao4\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "# Add a hidden layer with 784 neurons.\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(256, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=tf.nn.relu))\n",
    "\n",
    "# Add a 15 neuron output layer.\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62096/62096 [==============================] - 642s 10ms/step - loss: 1.5527 - acc: 0.5350\n",
      "Epoch 2/10\n",
      "62096/62096 [==============================] - 682s 11ms/step - loss: 0.5212 - acc: 0.8390\n",
      "Epoch 3/10\n",
      "62096/62096 [==============================] - 704s 11ms/step - loss: 0.2924 - acc: 0.9099\n",
      "Epoch 4/10\n",
      "62096/62096 [==============================] - 707s 11ms/step - loss: 0.2310 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "62096/62096 [==============================] - 684s 11ms/step - loss: 0.1931 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "62096/62096 [==============================] - 680s 11ms/step - loss: 0.1707 - acc: 0.9461\n",
      "Epoch 7/10\n",
      "62096/62096 [==============================] - 682s 11ms/step - loss: 0.1538 - acc: 0.9515\n",
      "Epoch 8/10\n",
      "62096/62096 [==============================] - 681s 11ms/step - loss: 0.1511 - acc: 0.9522\n",
      "Epoch 9/10\n",
      "62096/62096 [==============================] - 656s 11ms/step - loss: 0.1451 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "62096/62096 [==============================] - 616s 10ms/step - loss: 0.1233 - acc: 0.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ed6633ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Number of Epoch is the amount of times the training set is put through the model\n",
    "# The batch size is the amount of images the models processes at one time\n",
    "model.fit(X_train,y_train, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error percentage: 1.72%\n"
     ]
    }
   ],
   "source": [
    "# ------ Testing the model ------\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print(\"Error percentage: %.2f%%\" %(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.h5'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error percentage from loaded model: 1.72%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.h5'\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "scores = loaded_model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print(\"Error percentage from loaded model: %.2f%%\" %(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ee84cc780>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img = image.load_img('Dataset/KBND_A_2337.png')\n",
    "x = image.img_to_array(img)\n",
    "x = np.reshape(x,(1, 64, 64, 3))\n",
    "x = x.astype('float32')\n",
    "x = x/255\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-45a370e90858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "result = str(preds.argmax(axis=1))\n",
    "print(result)\n",
    "label_encoder.inverse_transform([argmax(result[2, :])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9581894e-11 1.4724127e-23 4.6861010e-10 2.2271201e-04 6.6897266e-14\n",
      "  5.4004889e-08 3.2686751e-10 2.7186646e-17 1.0786238e-04 2.0111224e-15\n",
      "  1.7191148e-08 9.9965739e-01 1.7806298e-09 1.1930257e-05 5.3199475e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
